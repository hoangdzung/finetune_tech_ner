# -*- coding: utf-8 -*-
"""zeroshot

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1jdsATrUZruxcJSvQooYbo5tFKtz-nQfw
"""

import torch
from torch.utils.data import IterableDataset
from transformers import AutoModelForSequenceClassification, AutoTokenizer

import json
from tqdm import tqdm
import argparse
import csv

parser = argparse.ArgumentParser()
parser.add_argument('--data')
parser.add_argument('--batch_size', type=int, default=32)
parser.add_argument('--out')
args=parser.parse_args()

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

nli_model = AutoModelForSequenceClassification.from_pretrained('facebook/bart-large-mnli',output_attentions=True).to(device)
tokenizer = AutoTokenizer.from_pretrained('facebook/bart-large-mnli')

class CustomIterableDataset(IterableDataset):

    def __init__(self, filename):
        self.filename = filename

    def __iter__(self):
        file_itr = open(self.filename)
        return file_itr

dataset     = CustomIterableDataset(args.data)
dataloader  = DataLoader(dataset, batch_size=args.batch_size)
HYPOTHESIS = 'This passage is about techonology'

with open(args.out, 'w', newline='') as f:
    csv_writer = csv.writer(f)
    for sequences in tqdm(dataloader):
    
        x = tokenizer(sequences, [HYPOTHESIS]*len(sequences),return_tensors='pt',
                            truncation_strategy='only_first', padding=True, truncation=True)
        logits=nli_model(x['input_ids'].to(device), x['attention_mask'].to(device))[0]
        entail_contradiction_logits = logits[:,[0,2]]
        probs = entail_contradiction_logits.softmax(dim=1)
        probs_label_is_true = probs[:,1].detach().cpu().numpy().tolist()
        csv_writer.writerows(list(zip(sequences, probs_label_is_true)))


